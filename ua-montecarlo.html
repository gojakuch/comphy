<html lang="ua">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ComPhy: Computational Physics Library</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
    <link href="style.css" rel="stylesheet" type="text/css" media="all">
    <link rel="icon" href="favicon.ico">
  </head>
  <body>
    <a href="index.html"><img alt="ComPhy" src="comphy.png" style="width:200px;height:100px"></a>
    <div class="main">
      <h1>Методи Монте-Карло</h1>
      <p>
        <b>Методи</b> або <b>симуляції Монте-Карло</b> – це великий клас, певна сукупність, алгоритмів та методів, що застосовують випадковість (рандом) для симуляції якогось процесу. Це може включати в себе як просту генерацію (псевдо)випадкового числа, так і навіть відомі <a href="https://uk.wikipedia.org/wiki/%D0%9C%D0%B0%D1%80%D0%BA%D0%BE%D0%B2%D1%81%D1%8C%D0%BA%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81">процеси Маркова</a> чи <a href="https://uk.wikipedia.org/wiki/%D0%9C%D1%83%D1%80%D0%B0%D1%88%D0%B8%D0%BD%D0%B8%D0%B9_%D0%B0%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC">мурашиний алгоритм</a>. На жаль, не так багато сказано по цій темі вкраїнською, тому в цій статті я розгляну декілька різноманітних алгоритмів, які можуть застосовуватись в обрахунковій фізиці. Методи Монте-Карло, загалом становлять велику частку від фізичних задач, що розв'язуються чисельно, адже застосовуються для чисельних експериментів.
      </p>
      <ol>
        <li><a href="#pi">Наближення π</a></li>
        <li><a href="#integral">Наближення інтегралу</a></li>
        <li><a href="#distributiongen">Генерація чисел за розподілом</a></li>
        <li><a href="#simulannealalgo">Алгоритм імітації відпалу</a></li>
      </ol>
      <h2 id="pi">Наближення π</h2>
      <p>
        Перші два розглянутих нами методи будуть стосуватися наближень, тобто наближених обчислень, а саме наближень площі (насправді вони майже ідентичні за логікою). Припускаю, що <b>цю частину статті зможе зрозуміти й школяр</b>. За допомогою наближення площі можна з непоганою точністю знайти значення числа π. Є декілька способів, утім, вони нічим, окрім геометричної інтерпретації, суттєво й не відрізняються.
      </p>
      <p>
        Для нашої симуляції уявимо собі певний прямокутник в системі координат, в якому ми й будемо працювати. Всередині цього робочого прямокутни виділимо дві окремих області, що не мають перетинатися: квадрат зі стороною \(a\) та коло з радіусом \(a\) (на ілюстрації нижче трохи викривлено масштаб).
      </p>
      <img style="display:block;margin:auto;height:auto;width:40%" src="img/ua-montecarlo/0.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 1</i> </div>
      <p>
        Позначимо загальну площу робочого прямокутника як \(S\), площу круга як \(S_O\), квадрата як \(S_K\). Звісно, \[\frac{S_O}{S_K} = \frac{πa^2}{a^2} = π\] Але нам також знадобиться поміркувати про інший дріб, що, очевидно, теж дорівнює π. \[\frac{S_O}{S}\cdot\frac{S}{S_K} = \frac{S_O}{S_K} = \frac{πa^2}{a^2} = π\]
      </p>
      <p>
        Алгоритм дій дуже простий: випадково обираємо точку \((x, y)\) в нашій робочій області, рахуючи, які точки потрапляють до кола, а які до квадрата.
      </p>
      <img style="display:block;margin:auto;height:auto;width:40%" src="img/ua-montecarlo/1.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 2</i> </div>
      <p>
        Позначимо кількість випадкових точок за \(N\), кількість точок у колі - \(O\), кількість точок у квадраті - \(K\). Припустимо, що ми взяли дуже велике \(N\). Імовірність точки потрапити до круга \(P_O = \frac{O}{N}\), до квадрата \(P_K = \frac{K}{N}\). Можна помітити, що теоретично \(P_O\) має приблизно дорівнювати частці площі круга відносно всієї зони \(\frac{S_O}{S}\). Аналогічно, для \(P_K\), \(\frac{K}{N} ≈ \frac{S_K}{S}\). З цього: \[\frac{O}{K} = \frac{O}{N}\cdot\frac{N}{K} = \frac{P_O}{P_K} ≈ \frac{S_O}{S}\cdot\frac{S}{S_K} = π\]
      </p>
      <p>
        Тобто, для наближення π нам достатньо поділити кількість випадкових точок, що потрапили до круга на кількість тих, що потрабили до квадрату. Звісно, \(N\) має бути великим. Хоча вже при такій кількости точок, як на малюнку нижче, наближення буде доволі точним.
      </p>
      <div style="text-align:center;display:block;margin:0 auto;">
        <img style="height:auto;width:30%" src="img/ua-montecarlo/3.png" alt="illustration">
        <img style="height:auto;width:30%" src="img/ua-montecarlo/4.png" alt="illustration">
      </div>
      <div style="text-align:center"> <i>Малюнки 3-4</i> </div>
      <p>
        Код мовою Julia, що використовувався для створення ілюстрацій, можна подивитися <a href="img/ua-montecarlo/jl.html" target="_blank">за цим посиланням</a>. Він навмисно написаний в явному вигляді, без особливих скорочень для збереження чіткости ідеї (також можете переглянути мій <a href="ua-julia.html">матеріял про саму мову Julia</a>). Альтернативно, ви можете написати дуже короткий код, як зроблено <a href="https://youtu.be/x7M1Q9US-5s">в цьому відео</a> (щоправда, мовою Python), де використовується геометрично інший метод.
      </p>
      <img style="display:block;margin:auto;height:auto;" src="img/ua-montecarlo/5.png" alt="illustration">
      <div style="text-align:center"> <i>Інший геометрично метод | <a href="https://youtu.be/x7M1Q9US-5s">source</a></i> </div>
      <code>
        <pre>
          <span class="cmnt"># julia</span>
          N = 300000000
          res = 4sum(rand(N).^2 .+ rand(N).^2 .< 1) / N
          <span class="cmnt">## генеруємо точки в одиничному квадраті, аби наблизити чверть площі одиничного кола, що становить π/4. потім множимо на 4.</span>
        </pre>
      </code>
      <h2 id="integral">Наближення інтегралу</h2>
      <p>
        Користуючись майже тими ж самими властивостями, ми можемо наближено обчислювати визначені інтеграли. Ми розглянемо приклад для функції однієї змінної, однак на практиці такий метод використовується лише для багатовимірних обчислень, адже для простіших задач існують більш точні методи апроксимації.
      </p>
      <p>
        Тож, припустимо, що ми хочемо обчислити \(\int^b_a f(x)dx\), тобто площу під графіком функції \(f(x)\), де \(С \ge f(x) \ge 0\) (узагальнити на не тільки додатні обмежені функції не складно) та \(f(x)\) інтегровна за Ріманом, на відрізку \([a, b]\), за допомогою випадкових точок та ймовірностей їх потрапляння під графік функції. При загальній площі робочої области \(S\), кількості випадково обраних точок \(N\), з яких \(F\) потрапили під графік функції та імовірності потрапляння \(P_f\) маємо \[\int^b_a f(x)dx = P_f \cdot S ≈ \frac{F}{N}\cdot S\]
      </p>
      <p>
        Єдина проблема залишається обрати межі робочої области. Насправді, "one can prove", як то кажуть, себто, можна довести, що найефективніше буде обрати прямокутник \([a, b]\times[0, \max{f(x)}]\), бо ми зробили припущення, що \(С \ge f(x) \ge 0\). Інтуїтивно, це просто найменший прямокутник, що містить весь підграфік функції, тобто нам знадобиться менше випадкових точок для точнішого обрахунку. Звісно, якщо наша функція розривна й у точці розриву "стрибає" далеко в гору, то це буде не зовсім коректно. Втім, рекомендую самостійно подумати над різними випадками, адже конкретна реалізація залежить від задачі: чи буває функція розривною, чи відомий максимум, чи легко знайти максимум чисельно тощо.
      </p>
      <div style="text-align:center;display:block;margin:0 auto;">
        <img style="height:auto;width:30%" src="img/ua-montecarlo/6.png" alt="illustration">
        <img style="height:auto;width:30%" src="img/ua-montecarlo/7.png" alt="illustration">
      </div>
      <div style="text-align:center"> <i>Малюнки 6-7: 100 точок та 200000 точок</i> </div>
      <p>
        Очевидно, що більше точок, то краще наближення. Цього разу одразу пропоную короткий код у якості демонстрації. Повний код, де розглянуто конкретну функцію, що використовувався для створення ілюстрацій – <a href="img/ua-montecarlo/jl2.html" target="_blank">за посиланням</a>. Зауважу, що там висота регіону підбирається вручну.
      </p>
      <code>
        <pre>
          <span class="cmnt"># julia</span>
          <span class="cmnt">## N - к-сть точок; f - функція; height - висота регіону; width - довжина регіону; S = height*width</span>
          points = [width*rand(N), height*rand(N)]
          F = sum(points[2] .< f.(points[1]))
          S_f = F/N*S
        </pre>
      </code>
      <h2 id="distributiongen">Генерація чисел за розподілом</h2>
      <p>
        При роботі з фізичними симуляціями та теорією ймовірности на комп'ютері, часто виникає потреба генерації випадкових чисел за певним розподілом. Сам комп'ютер, однак, вміє генерувати лише псевдорандомні числа з рівномірного розподілу. Тому було б непогано придумати метод, що дозволяє використовувати рівномірний розподіл для генерації чисел довільного розподілу. На щастя, в теорії ймовірностей існує гарна теорема, що допоможе нам це зробити (не лякайтесь формулювання).
      </p>
      <p>
        <b>Теорема (1):</b> Нехай \(X\) – випадкова величина з кумулятивною функцією розподілу ймовірностей \(F(x)\). Тоді випадкова величина, що задається як, \(F^{-1}(U)\), де \(U \in [0; 1]\) – випадкова рівномірна величина, також має кумулятивну функцію розподілу ймовірностей \(F(x)\). \[X \sim F(x) ⟹ F^{-1}(U) \sim F(x)\]
      </p>
      <p>
        Звучить, можливо, трохи незрозуміло, тому давайте розбиратися в інтуїції та зиску з цього твердження (доводити ми його не будемо). Якщо ми маємо випадкову  величину \(X\) (власне, яку ми й хочемо генерувати комп'ютерно) з функцією густини ймовірности \(f(x)\), то кумулятивна функція розподілу ймовірностей \(F(x) = \int^{x}_{-\infty} f(ξ) dξ\), тобто \(F(x_0)\) позначає ймовірність того що \(X < x_0\) і дорівнює, умовно, сумі ймовірностей значень до \(x_0\). Отже це певна неспадна функція (тому що ми сумуємо додатні ймовірності), значення якої належить \([0;1)\) (бо загальна ймовірність має бути менше за 1), що характеризує наш розподіл імовірностей. Тоді ця функція має обернену (в більшості випадків, принаймні коли ми говоримо про недискретну \(X\)).
      </p>
      <div style="text-align:center;display:block;margin:0 auto;">
        <img style="height:auto;width:30%" src="img/ua-montecarlo/8.png" alt="illustration">
        <img style="height:auto;width:30%" src="img/ua-montecarlo/9.png" alt="illustration">
      </div>
      <div style="text-align:center"> <i>Малюнки 8-9: Приклади графіків функцій</i> </div>
      <p>
        Помітимо, що \(F^{-1}(y)\) завжди визначена на \([0;1)\). За теоремою (1), генеруючи \(U \in [0; 1]\) за рівномірним розподілом та підставляючи у \(F^{-1}(U)\) будемо отримувати значення, альтернативні до \(X\), тобто ми можемо перейти до генерації \(U \in [0; 1)\) замість генерації \(X\), знаючи* \(F^{-1}(y)\). Генерація \(U\) здійснюється стандартним комп'ютерним методом псевдорандому, чи будь-яким іншим, який є простим і, що головне, можливим програмно.
      </p>
      <p>
        Додамо ще трохи інтуїтивного розуміння. Оберіть випадкове число від нуля до одного. Підставте це число до \(F^{-1}(y)\) (приблизно наочно за малюнком 9). Ви отримаєте якесь число. Імовірність отримати приблизно таке число описаним вище чином така сама, як і ймовірність того що \(X\) набуде цього значення.
      </p>
      <p>
        * – не обов'язково знати \(F^{-1}(y)\) у явному вигляді, хоча це трохи спрощує задачу. Достатньо знати \(F(x)\) й обчислити її на достатньо великій кількості значень, щоби замість обчислення \(F^{-1}(y_0)\) просто знаходити серед цих збережених значень найближче до \(y_0\) і повертати відповідний арґумент \(x_0\), аби \(F(x_0) \approx y_0\). При цьому пошуку не треба навіть обходити всі значення \(F(x)\), що ми записали, адже ми можемо використовувати <a href="https://uk.wikipedia.org/wiki/%D0%94%D0%B2%D1%96%D0%B9%D0%BA%D0%BE%D0%B2%D0%B8%D0%B9_%D0%BF%D0%BE%D1%88%D1%83%D0%BA">бінарний пошук</a>, бо збережені значення \(F(x)\) "відсортовані" через монотонність \(F(x)\).
      </p>
      <h2 id="simulannealalgo">Алгоритм імітації відпалу</h2>
      <p>
        Методи Монте-Карло можна також використовувати для машинного навчання. Особливо корисним це стає для вирішення дискретних задач за допомогою машинного навчання. Одним із простих ілюстративних алгоритмів для цього є алгоритм імітації відпалу. Складно кажучи, <b>алгоритм імітації відпалу</b> (з англ. Simulated Annealing) – це ймовірнісний метод апроксимації глобального оптимуму заданої функції. Простими словами, це випадковий метод розумного підбору відповіді для задачі. Саме пошук <i>глобального</i> оптимуму робить цей алгоритм цікавим, адже більшість методів апроксимації оптимуму шукають <i>локальний</i>.
      </p>
      <p>
        У цього алгоритму є як суто алгоритмічна сторона, так і фізичний сенс. Спочатку розглянемо його з математичної та алгоритмічної точки зору. Як і в більшості алгоритмів машинного навчання, ми задаємо певну функцію втрат (що вимірює помилку), що залежить від параметрів системи: \(L(P):\mathbb{P} \rightarrow \mathbb{R}\) (де \(\mathbb{P}\) – простір всіх можливих параметрів). Далі ми знаходимо її мінімум за параметрами системи, підбираючи таким чином набір параметрів \(P_{\text{min}} \in \mathbb{P}\), на якому наша модель помиляється найменше. Таким чином ми б "навчили" модель не сильно помилятися. Якщо б ми, починаючи з випадкової точки в просторі параметрів \(P_0 \in \mathbb{P}\), ітеративно рухалися лише "вниз" (тобто туди де \(L(P)\) набуває менших значень ніж у поточній точці), то ми б не ґарантовано дійшли б до глобального мінімуму, залишившись у локальному. Наприклад, якщо б \(L(P)\) була не опуклою на області параметрів, яку ми розглядаємо.
      </p>
      <img style="display:block;margin:auto;height:auto;width:40%" src="img/ua-montecarlo/10.gif" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 10: Пошук глобального мінімуму алгоритмом імітації відпалу. 500 ітерацій.</i> </div>
      <p>
        Алгоритм імітації відпалу вирішує цю проблему тим, що він випадковий. Тобто іноді може перестрибувати на нові точки в просторі параметрів. Вони можуть бути гірше, ніж поточна, однак у середньому це дає більше шансів знайти глобальний мінімум. <span class="cmnt">Якщо ви (раптом) чули про алгоритм Шьонінґа (Schöning's Algorithm) для SAT-задач, то це може чимось його нагадувати (якщо ні, то проігноруйте це речення).</span> Власне, сам алгоритм:
      </p>
      <p>
        \(P_i\) – поточний набір параметрів з \(\mathbb{P}\) <br>
        \(P\) – збережене припущення щодо оптимального набору параметрів з \(\mathbb{P}\) <br>
        \(\Delta P\) – деяка зміна для параметрів з \(\mathbb{P}\). Вона може обиратися випадково, або принаймні її знак має обиратися випадково. <br>
        УМОВА – загадкова умова для \(P_i\), про яку трохи згодом<br>
        <ol>
          <li>Обрати новий пробний стан \(P_{i} := P + \Delta P\)*</li>
          <li>
            Якщо (\(P_{i}\) краще** за \(P\)) або УМОВА:
            <ul><li>Перемістити \(P := P_{i}\)</li></ul>
          </li>
          <li>Повторити з першого кроку</li>
        </ol>
      </p>
      <p>
        * – Враховуючи, що \(\Delta P\) може обиратися випадково, можна просто випадково обирати \(P_i\)<br>
        ** – в нашому випадку, мається на увазі оцінка \(L(P_{i}) < L(P)\)
      </p>
      <p>
        Нумо розбиратися, що це означає. Ми робимо якесь початкове припущення щодо оптимуму \(P\). Далі обираємо якусь нову точку \(P_i\), трохи пересуваючись на \(\Delta P\) від \(P\). Якщо отримане \(P_i\) краще за наше припущення \(P\) (тобто якщо \(L(P_{i}) < L(P)\)), то ми міняємо \(P\) на \(P_i\). Якщо ж \(P_i\) гірше за наше припущення \(P\), то ми також можемо пересунути \(P\) на \(P_i\), у разі, якщо виконується певна УМОВА. Ця УМОВА й містить випадковість і суть алгоритму імітації відпалу.
      </p>
      <p>
        Не важко помітити, що від УМОВИ залежить можливість алгоритму "перестрибувати" до неоптимальних наборів параметрів. Ми хочемо, аби на початку алгоритму стрибки відбувалися частіше, щоби спробувати більше різних станів системи. Наприкінці ітерування ж, було б непогано пересуватися вже лише до кращих значень. Отже ймовірність далекого стрибку має обернено залежати від часу. Власне кажучи, ймовірність стрибнути задається розподілом Больцмана, тобто ось такою формулою: \[\frac{1}{1+\exp(\frac{\Delta L}{T(i)})}\] де: \(\Delta L = L(P_{i}) - L(P)\) є зміна цільової функції, в нашому випадку це \(L(P)\); \(T(i)\) – величина, залежна від часу (тобто номеру ітерації \(i\)), її називають <b>температурою системи</b>, така, що вона наближається до нуля з часом:
      </p>
      <img style="display:block;margin:auto;height:auto;width:40%" src="img/ua-montecarlo/11.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 11: Температура системи</i> </div>
      <p>
        При дуже високій температурі (на початку алгоритму), вираз \(\frac{\Delta L}{T(i)}\) прямує до нуля, \(\exp(\frac{\Delta L}{T(i)})\) прямує до 1, отже весь дріб \(\frac{1}{1+\exp(\frac{\Delta L}{T(i)})}\) прямує до \(\frac{1}{2}\). При малій температурі й додатньому \(\Delta L\) (тобто коли нові параметри \(P_i\) для нас гірші за обрані зараз \(P\), бо \(L(P_{i}) > L(P)\)), імовірність прямує до нуля. При малій температурі та від'ємному \(\Delta L\) (тобто коли нові параметри \(P_i\) кращі за обрані зараз \(P\)), імовірність прямує до 1, а значить ми стрибнемо до кращого набору параметрів. Отже, в самому алгоритмі не обов'язково навіть перевіряти, чи \(P_{i}\) краще за \(P\), адже УМОВА робить це, в якомусь сенсі, автоматично.
      </p>
      <p>
        Тепер поговоримо про фізичний сенс цього алгоритму. Справді, введення поняття "температури системи" натякає на фізичну інтерпретацію алгоритму. Помітимо, що УМОВА залежить не від часу, а від температури, яка, вже в свою чергу, залежить від часу. Сама ж назва алгоритму походить від відпалу в термообробці: нагрівання металу до критичної температури й повільне охолодження для того, щоб зробити матеріял міцнішим і стабільнішим.
      </p>
      <p>
        Маємо стан певної фізичної системи \(P\) та функцію енергії від стану \(L(P)\), отже задача може бути переформульована наступним чином: знайти стан системи, в якому енергія мінімальна (можна було б увести більш стандартні перепозначення, \(s\) та \(E(s)\), але я не буду нікого плутати). При цьому ми знижуємо температуру системи поступово.
      </p>
      <p>
        Як приклад, рекомендую ознайомитись із <a href="https://www.fourmilab.ch/documents/travelling/anneal/" target="_blank">інтерактивною статею</a>, де за допомогою цього алгоритму вирішується задача комівояжера. Алгоритм там можна налаштовувати майже будь-яким чином.
      </p>
    </div>

    <div style="text-align:center;padding-top:2%;"><a href="https://atell.neocities.org" style="color:grey">Atell Krasnopolski, 2022</a></div>
  </body>
</html>
