<!-- для статей українською файл має мати назву ua-ARTICLENAME.html -->
<html lang="ua">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ComPhy: Метод Зворотного Поширення Помилки</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
          src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
    <link href="style.css" rel="stylesheet" type="text/css" media="all">
    <link rel="icon" href="favicon.ico">
  </head>
  <body>
    <a href="index.html"><img alt="ComPhy" src="comphy.png" style="width:200px;height:100px"></a>

    <div class="main">
      <h1>Алгоритм Зворотного Поширення Помилки</h1><div style="text-align:center">та вступ до машинного навчання</div>
      <p>
        У цій статті я спробую пояснити доступно й українською ключовий алгоритм, що й дозволив увесь сучасний прогрес в області машинного навчання та штучного інтелекту — алгоритм зворотного поширення помилки (з англ. Backpropagation algorithm). Перш, ніж переходити до конкретних кроків та сенсу алгоритму, розберемося для чого застосовують цей алгоритм.
      </p>
      <p>
        Алгоритм зворотного поширення помилки, він же backprop, застосовується саме для процесу <i>навчання</i> штучних нейронних мереж і є надзвичайно ефективним для цього. Це <i>навчання</i> штучних нейронних мереж та інших параметризованих функцій (далі називатимемо це просто моделлю) є насправді просто чисельним пошуком параметрів, за яких наша модель помиляється найменше або не помиляється взагалі. Ми розіб'ємо цю важку тему на три частини:
      <ol>
        <li><a href="#models">Будова моделей, що навчаються</a></li>
        <li><a href="#GD">Навчання градієнтним спуском</a></li>
        <li><a href="#backprop">Алгоритм зворотного поширення помилки (нарешті)</a></li>
      </ol>
      </p>
      <p>
        Фокус, звісно ж, буде на останній частині, але щоб статтю могли прочитати також і ті, хто ще не знають про градієнтні методи, я вирішив додати трохи більше опису, тобто ми почнемо з загального опису машинного навчання. Загалом, відношення між цими темами можна описати наступним чином: у нас є моделі, що навчаються виконувати якусь задачу автоматично \(\rightarrow\) ми навчаємо їх за допомогою такого математичного об'єкту як градієнт \(\rightarrow\) використовуємо наш надзвичайно ефективний алгоритм backprop, щоб швидко порахувати градієнт. Себто, весь алгоритм — швидкий спосіб порахувати градієнти. А тепер про все по порядку.
      </p>

      <h2 id="models">Будова моделей, що навчаються</h2>

      <p>
        То що ж таке ці моделі, що навчаються? Уявімо, що в нас є певна задача для програми. У загальному вигляді, маємо вхідні дані \(x\) і хочемо, щоб програма видавала певні вихідні дані \(y\). Класичний приклад: ми даємо програмі курси валют за останні декілька днів, це наш \(x\), а програма має видавати курс валют на завтра, це \(y\). Через такі приклади, \(y\) часто називають <b>передбаченням</b> моделі (модель тут — просто наша програма).
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/1.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 1</i> </div>
      <p>
        Ви вже можете помітити певну схожість із функціями, об'єктами шкільної програми, через ось ці ікси та ігреки. І справді, будемо розглядати всю нашу модель (тобто програму) як певну функцію \(f\), що перетворює \(x\) на \(y\): \[f(x) = y\]
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/2.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 2</i> </div>
      <p>
        От тільки, як можна зрозуміти з нашого прикладу, ми, як правило, поняття не маємо, як описати цю функцію, що вирішує нашу задачу. Наші \(x\) та \(y\) можуть бути якимись авдіозаписами, картинками, текстом, будь-чим, що закодовано числами. Писати такі програми вручну — просто неможливо, ці функції \(f\) бувають неймовірно складними. Для цього ми й використовуємо так зване <b>машинне навчання</b>: ми прописуємо в коді вручну лише загальну структуру, тобто який вигляд має \(x\), який вигляд має \(y\), і певну загальну форму функції \(f\), а конкретна робоча програма утворюється автоматично в симульованому процесі навчання. У найпростішому випадку під навчанням мається на увазі підлаштування \(f\) під певні заготовлені приклади правильної роботи. Для такого процесу нам необхідно мати дві речі: якісь "налаштування" у функції \(f\), які ми власне будемо змінювати, та заготовлені приклади правильної роботи моделі, щоб розуміти, як саме ми маємо міняти параметри.
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/3.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 3</i> </div>
      <p id="dataset">
        А що ж це означає математично? Приклади роботи програми — це просто пари іксів та відповідних ігреків, які ми б вважали правильними: (\(\boldsymbol{x}_0;\boldsymbol{y}_0)\), (\(\boldsymbol{x}_1;\boldsymbol{y}_1)\),.. (\(\boldsymbol{x}_N;\boldsymbol{y}_N)\). Нагадую, що кожен \(\boldsymbol{x}_i\) та \(\boldsymbol{y}_i\) тут може бути набором чисел, для нас \(\boldsymbol{x}_i\) — це набір попередніх курсів валют, а \(y_i\) — одне число, курс валют на наступний день (зазвичай набори чисел позначають жирним шрифтом). Ці пари, як правило, беруться зі спостережень у реяльному світі, а ми очікуємо, що наша модель буде йому відповідати, тобто що для нашої функції в результаті буде виконуватися: \[f(\boldsymbol{x}_0) = \boldsymbol{y}_0\] \[f(\boldsymbol{x}_1) = \boldsymbol{y}_1\] \[...\] \[f(\boldsymbol{x}_N) = \boldsymbol{y}_N\] Загалом позначатимемо \(f(\boldsymbol{x}_i) = \boldsymbol{y}_i\). У прикладі з передбаченням курсу валют (який, до речі, є майже неможливим для реялізації, адже курси валют залежать від величезної кількости факторів окрім курсів попередніх днів) усі \(\boldsymbol{x}_i\) будуть деякими наборами однакової довжини з курсів валют попередніх днів, а відповідні \(y_i\) будуть курсами валют на наступний день. Тобто це реяльні числа, записані протягом певного часу, що мають саме ту відповідність, яку ми хочемо встановити за допомогою \(f\). Це називається <b>набором даних</b> (data set).
      </p>
      <p>
        Тепер поговоримо детальніше про ці "налаштування" у функції \(f\), що їх називають <b>вагами</b>. По суті, це будуть параметри функції. Якщо розглядати все зовсім початково, то наведу два приклади найпростіших функцій: параметризовану та без параметра: \[y = 5x+3 \text{; — просто лінійна функція}\] \[y = wx+1 \text{; — лінійна функція з параметром } w\] Параметрів може буде декілька (у випадку штучних нейронних мереж їх буде дуже багато): \[f(x) = wx+b \text{; — лінійна функція з двома параметрами }w,b\] Фіксуючи певні значення параметрів функції ми отримаємо непараметризовану функцію. Наприклад, зафіксувавши тут \(w = 5\), \(b = 3\), ми отримаємо нашу лінійну функцію з першого прикладу. Наша задаче буде зафіксувати такі параметри, що функція розв'язує задачу якнайкраще й помиляється якомога менше, хоча може й не ідеяльно<!-- (далі, весь набір таких параметрів, які ще називають вагами, позначатимемо просто \(\boldsymbol{w}\) або \(W\) від англійського weights)-->.
      </p>
      <p>
        Лінійна функція \(f(x) = wx+b\) була б занадто простою, щоб вирішувати сучасні задачі (не кажучи вже про те, що це просто числова функція, а навіть у нашому прикладі трохи інша ситуація). Нам потрібно більше параметрів, нелінійність та правильні розмірності \(\boldsymbol{x}\) та \(\boldsymbol{y}\). Поки що розберімося з розмірностями: у нашому прикладі \(\boldsymbol{x}\) — упорядкований набір чисел, тобто вектор з дійсних чисел, а \(y\) — одне число. Отже, наша функція має приймати вектор певної кількости чисел (розмірности) та видавати 1 число (але бувають й інші випадки). Перетворювати вектор на число чи вектор іншої довжини можна й лінійними функціями, хоча й більш складнішими. У загальному випадку, лінійна частина штучної нейронної мережі має форму
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/nn.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 4.0</i> </div>
      <p>
        Тобто це набір лінійних зв'язків між двома шарами <b>числових нейронів</b>. Кожному нейрону відповідає число у векторі. Ми беремо наш вхідний вектор, і робимо декілька чисел, які групуємо у вихідний (тобто розмірність вихідного вектора обираємо потрібну). Ці числа ми робимо за допомогою параметризованих лінійних функцій, що просто комбінують всі значення вхідного вектора. Наприклад, значення нейронів вихідного шару формуватиметься як \[y_1 = w_{1,1}x_1 + w_{1,2}x_2 + ... + w_{1,n}x_n + b_1\] \[...\] \[y_m = w_{m,1}x_1 + w_{m,2}x_2 + ... + w_{m,n}x_n + b_m\] де кожне \(x_i\) — значення відповідного нейрону вхідного шару (тобто відповідний елемент у вхідному векторі). Як бачимо, кожне значення з нейрону попереднього шару \(x_i\) множиться на якийсь параметр \(w_i\) і комбінується з додатковим власним доданком \(b_1\). Це навіяно сигналами природніх нейронів у мозку: нейрон приймає сигнали з сусідніх і формує свій сигнал, враховуючи сигнали інших з якимись коєфіцієнтами. Тобто якісь нейрони під номером \(i\) мало впливають на сигнал інших, якщо відповіний множник \(w_i\) близький до нуля, а якісь навпаки сильно впливають, якщо цей множник \(w_i\) великий. Для всіх нейронів одного шару одночасно (себто, у векторній формі) це можна описати як
        \[\boldsymbol{y} = W\boldsymbol{x} + \boldsymbol{b}\] де \(\boldsymbol{x}\) — вектор "вхідної" розмірности \(n\) (відповідно й кількість вхідних нейронів), \(\boldsymbol{b}\) — вектор параметрів "вихідної" розмірности \(m\) (скільки нейронів на виході), а \(W\) — матриця параметрів (таблиця параметрів \(m \times n\)).
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/4.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 4.1</i> </div>
      <p>
        Наразі я не буду надто глибоко пояснювати, як працює множення матриці на вектор \(W\boldsymbol{x}\), лише скажу, що геометрично результатом такої операції є збільшення/зменшення та/або поворот вектора \(\boldsymbol{x}\), тобто ці параметри \(W\) впливатимуть на кут повороту та конкретний розтяг вектора. Якщо вас це заплутує, то пропустіть це. Для кращого розуміння матриць та векторів раджу продивитися <a href="https://youtube.com/playlist?list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B" target="_blank">найкращий візуальний вступний курс лінійної алгебри англійською</a> (є українські субтитри на деяких відео) або шукати схожі матеріяли про лінійну алгебру українською.
      </p>
      <p>
        Ми, як правило, будуємо певний ланцюг таких шарів з нейронів (тобто лінійних шарів), застосовуючи нелінійні функції до значення кожного нейрону після кожного шару (наприклад, якусь нелінійну функцію \(a\), що називається <b>функцією активації</b>). Це сформує штучну нейронну мережу, тобто параметризовану функцію, що здатна вивчати складні відповідності між \(\boldsymbol{x}\) та \(\boldsymbol{y}\) — уже класичний приклад моделі, що навчається.
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/nn2.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 4.2</i> </div>
      <p>
        На малюнку 4.2: 
        \[\boldsymbol{h} = a(W_1\boldsymbol{x} + \boldsymbol{b}_1) \text{; — перший шар, проміжний результат}\]
        \[\boldsymbol{y} = W_2\boldsymbol{h} + \boldsymbol{b}_2 \text{; — другий шар, результат обчислень}\]
      </p>
      <p>
        Або в один рядок \[f(\boldsymbol{x}) = W_2a(W_1\boldsymbol{x} + \boldsymbol{b}_1) + \boldsymbol{b}_2\] А далі, після того, як ми визначилися зі структурою нашої моделі (кількістю шарів та розміром проміжних, який може бути майже довільним), наша задача зводиться до підбору правильних параметрів \(W_i\) та \(\boldsymbol{b}_i\), за яких модель помиляється найменше. Іншими словами, нам потрібно навчити нейрони звертати увагу на потрібні елементи вхідного вектору й виконувати необхідні обчислення.
      </p>
      <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-backprop/5.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 5</i> </div>

      <h2 id="GD">Навчання градієнтним спуском</h2>
      <p>
        Отже, ми побудували нашу модель, визначили її архітектуру, кількість параметрів (установлюється залежно від величини та кількості внутрішніх шарів), обрали нелінійну функцію, яку застосовуємо між шарами. Питання, яке виникає далі в читача, яке виникало спочатку в мене та, сподіваюся, виникло у вас: «То як нам знайти значення цих параметрів?». Відповідаю. Початково ми ставимо всі параметри на довільні числа, тобто обираємо випадкову (чи яку хочемо) конфігурацію моделі. Можливо всі нулі, можливо всі одиниці, можливо просто якісь різні випадкові числа від 0 до 1 (так частіше за все й роблять), але якось заповнюємо параметри \(W\) та \(\boldsymbol{b}\).<!--(* — тут уявимо, що в нас \(k\) шарів, кожен має вигляд, описаний у попередньому параграфі)-->. Чи буде така модель правильною? Ну, тільки якщо нам одразу повезе підібрати такі параметри, але нам наразі просто треба з чогось почати. Коли ми маємо бодай якусь модель, ми вже можемо її випробувати на нашому наборі даних. А далі ми будемо покращувати модель за допомогою навчання, повторюючи процес навчання багато разів, тому початкові параметри нас не дуже цікавлять (ну, майже).
      </p>
      <p>
        Для процесу навчання нам необхідно оцінювати, наскільки неправильно працює модель за наших параметрів і намагатися змінити параметри так, щоб мінімізувати похибку роботи моделі. Спочатку похибка буде величезною, бо наша параметризована функція ніяк не підлаштована до нашої задачі й множить якісь випадкові числа на наші вхідні дані. Однак, за допомогою так званого <b>методу градієнтного спуску</b> ми будемо поступово, крок за кроком, покращувати параметри. Подивимося, як оцінювати похибку моделі. По-перше, ми розглядаємо нашу модель як деяку функцію, яка залежить від параметрів \(W\) та \(\boldsymbol{b}\): \[\hat{\boldsymbol{y}} = f(\boldsymbol{x}; W, \boldsymbol{b})\] де \(\hat{\boldsymbol{y}}\) — передбачення моделі для \(\boldsymbol{x}\) за заданих параметрів \(W, \boldsymbol{b}\). По-друге, нагадаю, що в нас є певний набір правильних (бажаних) результатів роботи моделі (\(\boldsymbol{x}_0;\boldsymbol{y}_0)\), (\(\boldsymbol{x}_1;\boldsymbol{y}_1)\),.. (\(\boldsymbol{x}_N;\boldsymbol{y}_N)\), під який ми підлаштовуватимемо модель. Тобто бажаний результат – знайти такі набори параметрів \(W*\), \(\boldsymbol{b}*\), що для кожної пари прикладів ікса та ігрека виконуватиметься: \[\boldsymbol{y}_i \approx \hat{\boldsymbol{y}}_i\] Тобто правильний ігрек приблизно дорівнює відповідному передбаченню моделі. Це те саме, що \[\boldsymbol{y}_i \approx f(\boldsymbol{x}_i; W*, \boldsymbol{b}*)\] тоді \[\boldsymbol{y}_i - f(\boldsymbol{x}_i; W*, \boldsymbol{b}*) \approx \boldsymbol{0}\] тоді також \[||\boldsymbol{y}_i - f(\boldsymbol{x}_i; W*, \boldsymbol{b}*)|| \approx 0\] Тут ми беремо модуль (точніше, норму, але я поки це проігнорую), щоб позначити, що нам не важливо, в якому напрямку відхилення (умовно, чи наша модель перебільшує чи применшує), але важливо позначити різницю між тим, що видала модель для нашого \(\boldsymbol{x}_i\) та значенням з прикладу \(\boldsymbol{y}_i\).
      </p>
      <p>
        Насправді ми щойно майже те й зробили, що оцінили похибку. Проблема лиш у тому, що ми оцінили похибку лише для окремої пари (\(\boldsymbol{x}_i;\boldsymbol{y}_i)\) та конкретних параметрів \(W*\), \(\boldsymbol{b}*\), ось ця похибка: \(||\boldsymbol{y}_i - f(\boldsymbol{x}_i; W*, \boldsymbol{b}*)||\). Справді, це невід'ємне число, що дорівнює 0 лише коли наша модель НЕ помилилася, а інакше характеризує, наскільки ж помилилася, тобто відхилилася від правильної відповіді \(\boldsymbol{y}_i\), наша модель. Повна похибка для певного набору параметрів \(W\), \(\boldsymbol{b}\) буде просто середнім з похибок на всіх парах прикладів: \[\frac{||\boldsymbol{y}_0 - f(\boldsymbol{x}_0; W, \boldsymbol{b})|| + ||\boldsymbol{y}_1 - f(\boldsymbol{x}_1; W, \boldsymbol{b})|| + ... + ||\boldsymbol{y}_N - f(\boldsymbol{x}_N; W, \boldsymbol{b})||}{N+1}\] Враховуючи, що дріб залежить лише від параметрів \(W\) та \(\boldsymbol{b}\) і по суті оцінює середню похибку на них, можемо визначити функцію: \[L(W, \boldsymbol{b}) = \frac{||\boldsymbol{y}_0 - f(\boldsymbol{x}_0; W, \boldsymbol{b})|| + ||\boldsymbol{y}_1 - f(\boldsymbol{x}_1; W, \boldsymbol{b})|| + ... + ||\boldsymbol{y}_N - f(\boldsymbol{x}_N; W, \boldsymbol{b})||}{N+1}\] Цю функцію, що рахує похибку за певних параметрів, називають <b>функцією витрат</b>. Її можна визначати й трохи по-іншому, але сенс один: ми маємо знайти такі параметри, щоб її значення було близьким до мінімального (тобто мінімізувати її). Для простоти, щоб не розглядати її як функцію від двох змінних, знехтуємо параметрами \(\boldsymbol{b}\), отримавши певну функцію \(L(W)\) (все одно \(W\) — набір з параметрів, а не один, просто вважаймо, що \(W\) тепер — усі параметри разом).
      </p>
      <p>
        Далі застосуймо градієнтний спуск до \(L(W)\), щоб знайти її мінімум. Для чого нам якісь складні алгоритми? От подумайте, чи зможете ви вручну підібрати мінімум для нелінійної функції з 50 параметрів? У задачах машинного навчання ми ніколи не знаємо де саме в просторі можливих параметрів знаходяться оптимальні для нашої задачі, бо простір цей величезний, а задачі дуже складні. Як же працює цей чудовий метод? На щастя, тут є красива графічно зрозуміла частина та інтуїтивна ідея.
      </p>
      <p>
        Розглянемо якийсь ілюстративний графік \(L(W)\). У неї чітко видно мінімум, тобто оптимальний для нас набір параметрів. Нашу початкову випадкову здогадку про параметри відмічено стрілочкою, позначимо ці параметри \(W_0\), відповідно похибка на цьому наборі параметрів буде \(L(W_0)\).
      </p>
      <img style="display:block;margin:auto;height:auto;width:35%" src="img/ua-backprop/graph0.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 6</i> </div>
      <p>
        Принцип роботи градієнтного спуску дуже простий: ми стоїмо в якійсь точці на хилястій поверхні (для нас це \(W_0\)) й хочемо спуститися якомога нижче. Робитимемо один крок у напрямку найбільш похилого спуску, щоб опинитися одразу якнайнижче. Опиняємося після кроку в новій точці, з якої повторюємо процес. Повторюємо купу разів або допоки не досягли достатньо низької точки. На графіку це виглядатиме так:
      </p>
      <img style="display:block;margin:auto;height:auto;width:35%" src="img/ua-backprop/graph1.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 7</i> </div>
      <p>
        У нашій одновимірній ілюстрації є лише два напрямки: праворуч та ліворуч, тому ситуація трохи спрощуєься. З нашої точки, щоб спускатися кривою похибки, ми рухатимемо параметри лише праворуч. Крок параметру намальовано помаранчевим.
      </p>
      <p>
        Утім, навіть у двовимірному випадку (а як правило в нас дуже багато параметрів \(W\)), кількість можливих напрямків для кроку стає неперераховною, а треба знайти оптимальний напрямок. Просто для прикладу, хилясту поверхню функції \(L(W)\) у двох вимірах (а також спуск з якоїсь її точки) можна уявити так:
      </p>
      <img style="display:block;margin:auto;height:auto;width:35%" src="img/ua-backprop/graph2.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 8</i> </div>
      <p>
        Тут також проілюстровано проблему вибору напрямку найкрутішого спуску. Для її вирішення та фінального формального й математичного опису алгоритму повернімося в наш одновимірний приклад. Як зрозуміти з цієї точки, у який бік (праворуч чи ліворуч) буде спуск? Зі шкільної програми (у теорії) знаємо про таку чудову річ як похідна! Формально, похідна — це тангенс кута нахилу дотичної прямої до графіку функції в цій точці. Для нас тут важливо те, що це число, що характеризує кут нахилу. Якщо похідна в цій точці додатна — функція зростає, отже для спуску треба робити крок ліворуч. Якщо від'ємна — функція спадає, отже треба робити крок праворуч. Припускаємо, що для нашої функції похідна існує й усе добре.
      </p>
      <img style="display:block;margin:auto;height:auto;width:35%" src="img/ua-backprop/graph3.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 9</i> </div>
      <p>
        На малюнку 9 є приклади точок із різним знаком похідної та показано напрямок, у якому ми б рухали параметри вниз відносно чих точок. Тепер опишемо правило кроку градієнтного спуску математично, за допомогою формули. Формула буде задавати, як саме ми маємо змінити \(W\) далі. От знаходимося ми на якійсь точці \(W_n\), десь посередині алгоритму і хочемо дізнатися наступну точку \(W_{n+1}\), яка буде (нам би так хотілося) оптимальніше поточної. Отже, задача: виразити \(W_{n+1}\) через \(W_n\), щоб дізнатися наступну точку, знаючи поточну. У який бік ми маємо рухатися відносно точки \(W_n\)? Як ми виявили, у протилежний до знаку похідної! Нагадую: додатна похідна — рухаємося ліворуч, тобто віднімаємо якийсь крок; від'ємна похідна — рухаємося праворуч, тобто додаємо якийсь крок. Тоді похідна \(L'(W_n)\) функції втрат у точці \(W_n\) має входити до формули з протилежним знаком (доставляємо мінус). Виходить: \[W_{n+1} = W_n - \alpha L'(W_n)\] де \(\alpha > 0\) — число, що задає крок. Зазначу, що крок не буде дорівнювати \(\alpha\), але більше \(\alpha\) — більший крок. Як правило, ми беремо дуже мале альфа, щоб не пропустити наш мінімум, але не надто мале, щоб не довго йти.
      </p>
      <p>
        Тепер ми знаємо, як спускатися в одновимірному випадку (припустимо \(\alpha=0.01\)): починаємо з випадкової першої точки (параметру) \(W_0\) і проганяємо формулу, отримуючи кращі точки (параметри): \[W_1 = W_0 - 0.01 L'(W_0)\] \[W_2 = W_1 - 0.01 L'(W_1)\] \[...\] У такому одновимірному випадку похідну в кожній точці можна шукати на комп'ютері приблизно за означенням, за формулою \(L'(W_n) \approx \frac{L(W_n) - L(W_n+h)}{h}\) при дуже малих і близьких до нуля (але не саме нульових) значеннях \(h\), але в цій статті ми про це говорити не будемо. Вважайте, що це для особливо допитливих.
      </p>
      <p>
        У нас має виникнути два питання: чи змінюється формула в реальних багатовимірних задачах і чому спуск градієнтний? Відповідь одна — формула змінюється, але не сильно: похідна стає <b>градієнтом</b>, певним узагальненням похідної. Позначатимемо його (градієнт \(L\) у точці \(W_n\)) так: \(\nabla L(W_n)\). Отже загальна формула: \[W_{n+1} = W_n - \alpha \nabla L(W_n)\] Градієнт — це векторний аналог похідної. Простими словами, він показує нам той самий напрямок, що й похідна в одновимірному просторі, тому його теж треба брати з мінусом. Обчислювати градієнт можна різними способами, але нас цікавить найкращий: алгоритм зворотного поширення помилки.
      </p>
      <p>
        Перед цим скажу, що в градієнтного спуску є певні мінуси як у методу оптимізації. Він не гарантовано знаходить найкращий, глобальний, мінімум, тобто може застрягти не в тому місці, якщо нам непощастить із початковою точкою:
      </p>
      <img style="display:block;margin:auto;height:auto;width:35%" src="img/ua-backprop/graph4.png" alt="illustration">
      <div style="text-align:center"> <i>Малюнок 10</i> </div>
      <p>
        Ось, наприклад, у нашому прикладі \(L(W)\) є така інша точка \(W_0\), почавши з якої ми теоретично й дійдемо до певного мінімуму \(W*\), але це буде локальний мінімум, тобто, як бачимо, помилятися там наша модель ще буде дуже сильно (\(L(W*)\) знаходиться доволі високо). Із точки \(W*\) градієнтний спуск уже нікуди не піде, бо будь-який крок звідти — крок угору, а він може лише спускатися (бо це ж спуск). Математично це пояснюється тим, що похідна (градієнт) у тій точці буде нульова.
      </p>

      <h2 id="backprop">Алгоритм зворотного поширення помилки (нарешті)</h2>
      <p>[Незабаром]</p>

      <!--     <img style="display:block;margin:auto;height:auto;width:25%" src="img/ua-ARTICLENAME/IMGNUMBER.png" alt="illustration">
      <div style="text-align:center"> <i>CAPTION</i> </div>     -->

    </div><!-- кінець мейну -->


    <div style="text-align:center;padding-top:2%;"><a href="https://atell.neocities.org" style="color:grey">Atell Krasnopolski, 2023</a><br><a rel="license" href="http://creativecommons.org/licenses/by-nc/3.0/deed.uk" target="_blank"><img alt="Creative Commons Licence" style="border-width:0" src="http://i.creativecommons.org/l/by-nc/3.0/88x31.png"></a></div>
  </body>
</html>
